---
title: "DA 301"
output: html_document
date: "2024-11-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# Load libraries
library(dplyr)
library(glmnet)

#read data
data <- read.csv("new_jump_data.csv")
unique(data$injury_type)

# Remove columns that are entirely NA
data <- data[, colSums(is.na(data)) < nrow(data)]
```


```{r}
#Check for remaining NAs and decide on further handling (e.g., impute or remove rows with NAs in key metrics)
summary(data)
```

```{r}
# Example: Creating a binary variable for injury/fatigue status
data$Injured <- ifelse(data$injury_type == "NA", 0, 1)
data$Injured[is.na(data$Injured)]<- 0 

# Check distribution of the target variable
table(data$Injured)

```

There are 5043 athletes who are injured out of 10967 athletes in the dataset.

## LOGISTIC REG WITH LASSO
```{r}
# Filter numeric columns only
numeric_data <- data[sapply(data, is.numeric)]
numeric_data <- na.omit(numeric_data)


# Split the data into training and testing sets (70% train, 30% test)
set.seed(123)  # for reproducibility
train_indices <- sample(seq_len(nrow(numeric_data)), size = 0.7 * nrow(numeric_data))
train_data <- numeric_data[train_indices, ]
test_data <- numeric_data[-train_indices, ]

# Separate predictors (X) and outcome variable (y) in training and testing data
X_train <- as.matrix(train_data[, -which(names(train_data) == "Injured")])  # Exclude the target variable
y_train <- as.factor(train_data$Injured)

X_test <- as.matrix(test_data[, -which(names(test_data) == "Injured")])  # Exclude the target variable
y_test <- as.factor(test_data$Injured)

# Fit the lasso logistic regression model with cross-validation to find the best lambda
cv_lasso <- cv.glmnet(X_train, y_train, family = "binomial", alpha = 1)
best_lambda <- cv_lasso$lambda.min
best_lambda
```


```{r}
# Refit the model using the best lambda
lasso_model_best <- glmnet(X_train, y_train, family = "binomial", alpha = 1, lambda = best_lambda)

# Predict on the test set based on threshold
predicted_prob <- predict(lasso_model_best, newx = X_test, type = "response")

# ROC curve
library(pROC)
roc_curve <- roc(y_test, predicted_prob)
plot(roc_curve, main = "ROC Curve", col = "black", best=TRUE)

```



```{r}
coords(roc_curve, "best", ret = "threshold")
```
```{r}
predicted_class <- ifelse(predicted_prob > 0.422593	, 1, 0) #thresshold of 0.422593
```



```{r}
# Generate the confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = y_test)
conf_matrix
```


```{r}
# Calculate accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
cat("Accuracy:", accuracy, "\n")
```


```{r}
# Extract non-zero coefficients to interpret the model
coef <- coef(lasso_model_best)
non_zero_coef <- coef[coef != 0]
print("Non-zero coefficients:")
non_zero_coef
#coef
```


```{r}
# Extracting coefficients from the lasso model
coef_data <- as.matrix(coef(lasso_model_best))

# Convert sparse matrix to a regular matrix
coef_data <- as.matrix(coef_data)

# Convert it to a data frame for easier manipulation
coef_df <- data.frame(Coefficient = coef_data[, 1])
coef_df$Feature <- rownames(coef_df)

# Remove the intercept row and zero coefficients
coef_df <- coef_df[coef_df$Feature != "(Intercept)" & coef_df$Coefficient != 0, ]

# Sort the coefficients by absolute value and select top 10
top_coef_df <- coef_df[order(abs(coef_df$Coefficient), decreasing = TRUE), ][1:10, ]

# Plotting the top 10 most important features
library(ggplot2)
ggplot(top_coef_df, aes(x = reorder(Feature, abs(Coefficient)), y = Coefficient)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 10 Lasso Model - Most Important Features",
       x = "Features",
       y = "Coefficient Value") +
  theme_minimal()

```




