{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil import parser\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "data = pd.read_csv(\"./new_jump_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "next_injury\n",
      "0    0.716931\n",
      "1    0.283069\n",
      "Name: proportion, dtype: float64\n",
      "Warning: Fold 1 contains only one class in training data\n",
      "Warning: Fold 2 contains only one class in test data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have at least 1 validation dataset for early stopping.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 248\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass distribution:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    247\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m EnsembleInjuryPredictor(weights\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.3\u001b[39m])\n\u001b[0;32m--> 248\u001b[0m fold_metrics, overall_metrics, predictions, true_values \u001b[38;5;241m=\u001b[39m \u001b[43mensemble\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOverall Metrics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Â± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_auc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 124\u001b[0m, in \u001b[0;36mEnsembleInjuryPredictor.train_and_evaluate\u001b[0;34m(self, X, y, n_splits)\u001b[0m\n\u001b[1;32m    122\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_train_scaled, label\u001b[38;5;241m=\u001b[39my_train)\n\u001b[1;32m    123\u001b[0m dtest \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_test_scaled, label\u001b[38;5;241m=\u001b[39my_test)\n\u001b[0;32m--> 124\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m xgb_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(dtest)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# Train LightGBM\u001b[39;00m\n",
      "File \u001b[0;32m~/stuff/DD/Y3S1/DA-301/random /.venv/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/stuff/DD/Y3S1/DA-301/random /.venv/lib/python3.12/site-packages/xgboost/training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    185\u001b[0m bst \u001b[38;5;241m=\u001b[39m cb_container\u001b[38;5;241m.\u001b[39mafter_training(bst)\n",
      "File \u001b[0;32m~/stuff/DD/Y3S1/DA-301/random /.venv/lib/python3.12/site-packages/xgboost/callback.py:261\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    259\u001b[0m     metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[0;32m--> 261\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/stuff/DD/Y3S1/DA-301/random /.venv/lib/python3.12/site-packages/xgboost/callback.py:261\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m     metric_score \u001b[38;5;241m=\u001b[39m _parse_eval_str(score)\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history(metric_score, epoch)\n\u001b[0;32m--> 261\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/stuff/DD/Y3S1/DA-301/random /.venv/lib/python3.12/site-packages/xgboost/callback.py:446\u001b[0m, in \u001b[0;36mEarlyStopping.after_iteration\u001b[0;34m(self, model, epoch, evals_log)\u001b[0m\n\u001b[1;32m    444\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have at least 1 validation dataset for early stopping.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(evals_log\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Get data name\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata:\n",
      "\u001b[0;31mValueError\u001b[0m: Must have at least 1 validation dataset for early stopping."
     ]
    }
   ],
   "source": [
    "def prepare_data(df):\n",
    "    date_columns = ['Date', 'problem_date', 'return_date', 'reported_date']\n",
    "    df = df.dropna(subset=date_columns)\n",
    "    \n",
    "    for col in date_columns:\n",
    "        df.loc[:,col] = [parser.parse(date) for date in df[col]]\n",
    "    \n",
    "    df = df.sort_values('Date')\n",
    "    \n",
    "    df['next_injury'] = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        future_injuries = df[\n",
    "            (df['problem_date'] > row['Date']) & \n",
    "            (df['problem_date'] <= row['Date'] + pd.Timedelta(days=14))\n",
    "        ]\n",
    "        if len(future_injuries) > 0:\n",
    "            df.at[idx, 'next_injury'] = 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    exclude_cols = ['Date', 'problem_date', 'return_date', 'reported_date', \n",
    "                    'next_injury', 'athlete_code', 'TestId']\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols and \n",
    "                   df[col].dtype in ['float64', 'int64']]\n",
    "    \n",
    "    X = df[feature_cols].ffill().replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    y = df['next_injury']\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "class EnsembleInjuryPredictor:\n",
    "    def __init__(self, weights=None):\n",
    "        self.weights = weights if weights is not None else [1/3, 1/3, 1/3]\n",
    "        \n",
    "        # Initialize models with class imbalance handling\n",
    "        self.rf_params = {\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 6,\n",
    "            'random_state': 42,\n",
    "            'class_weight': 'balanced_subsample',\n",
    "            'min_samples_leaf': 5\n",
    "        }\n",
    "        \n",
    "        self.xgb_params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'max_depth': 6,\n",
    "            'eta': 0.1,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        self.lgb_params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.1,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 1,\n",
    "            'is_unbalance': True,\n",
    "            'verbose': -1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        self.rf_model = RandomForestClassifier(**self.rf_params)\n",
    "        self.feature_importances_ = None\n",
    "        \n",
    "    def safe_predict_proba(self, model, X, fallback_pred=None):\n",
    "        try:\n",
    "            probs = model.predict_proba(X)\n",
    "            if probs.shape[1] == 2:\n",
    "                return probs[:, 1]\n",
    "            else:\n",
    "                return np.zeros(len(X)) if fallback_pred is None else fallback_pred\n",
    "        except:\n",
    "            return np.zeros(len(X)) if fallback_pred is None else fallback_pred\n",
    "    \n",
    "    def train_and_evaluate(self, X, y, n_splits=5):\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        \n",
    "        all_predictions = []\n",
    "        all_true_values = []\n",
    "        feature_importances = []\n",
    "        fold_metrics = []\n",
    "        \n",
    "        # Calculate class weight for XGBoost\n",
    "        neg_pos_ratio = np.sum(y == 0) / np.sum(y == 1)\n",
    "        self.xgb_params['scale_pos_weight'] = neg_pos_ratio\n",
    "        \n",
    "        for fold, (train_idx, test_idx) in enumerate(tscv.split(X), 1):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            # Check if both classes are present\n",
    "            if len(np.unique(y_train)) < 2:\n",
    "                print(f\"Warning: Fold {fold} contains only one class in training data\")\n",
    "                continue\n",
    "            \n",
    "            if len(np.unique(y_test)) < 2:\n",
    "                print(f\"Warning: Fold {fold} contains only one class in test data\")\n",
    "                continue\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Train Random Forest\n",
    "            self.rf_model.fit(X_train_scaled, y_train)\n",
    "            rf_pred = self.safe_predict_proba(self.rf_model, X_test_scaled)\n",
    "            \n",
    "            # Train XGBoost without early stopping\n",
    "            dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "            dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "            xgb_model = xgb.train(\n",
    "                self.xgb_params,\n",
    "                dtrain,\n",
    "                num_boost_round=100,\n",
    "                evals=[(dtrain, 'train')],\n",
    "                verbose_eval=False\n",
    "            )\n",
    "            xgb_pred = xgb_model.predict(dtest)\n",
    "            \n",
    "            # Train LightGBM\n",
    "            train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "            lgb_model = lgb.train(\n",
    "                self.lgb_params,\n",
    "                train_data,\n",
    "                num_boost_round=100\n",
    "            )\n",
    "            lgb_pred = lgb_model.predict(X_test_scaled)\n",
    "            \n",
    "            # Ensemble predictions\n",
    "            ensemble_pred = (\n",
    "                self.weights[0] * rf_pred +\n",
    "                self.weights[1] * xgb_pred +\n",
    "                self.weights[2] * lgb_pred\n",
    "            )\n",
    "            \n",
    "            # Calculate metrics\n",
    "            auc_score = roc_auc_score(y_test, ensemble_pred)\n",
    "            precision, recall, _ = precision_recall_curve(y_test, ensemble_pred)\n",
    "            pr_auc = auc(recall, precision)\n",
    "            \n",
    "            fold_metrics.append({\n",
    "                'fold': fold,\n",
    "                'auc': auc_score,\n",
    "                'pr_auc': pr_auc,\n",
    "                'positive_ratio': np.mean(y_test)\n",
    "            })\n",
    "            \n",
    "            # Store predictions and true values\n",
    "            all_predictions.extend(ensemble_pred)\n",
    "            all_true_values.extend(y_test)\n",
    "            \n",
    "            # Get feature importances\n",
    "            rf_importance = self.rf_model.feature_importances_\n",
    "            \n",
    "            # Get XGBoost feature importance\n",
    "            xgb_importance = np.zeros(X.shape[1])\n",
    "            for feat, imp in xgb_model.get_score(importance_type='gain').items():\n",
    "                xgb_importance[int(feat.replace('f', ''))] = imp\n",
    "            \n",
    "            # Get LightGBM feature importance\n",
    "            lgb_importance = lgb_model.feature_importance(importance_type='gain')\n",
    "            \n",
    "            # Normalize importances\n",
    "            rf_importance = rf_importance / rf_importance.sum()\n",
    "            xgb_importance = xgb_importance / (xgb_importance.sum() or 1)\n",
    "            lgb_importance = lgb_importance / (lgb_importance.sum() or 1)\n",
    "            \n",
    "            # Combine feature importances\n",
    "            fold_importance = (\n",
    "                self.weights[0] * rf_importance +\n",
    "                self.weights[1] * xgb_importance +\n",
    "                self.weights[2] * lgb_importance\n",
    "            )\n",
    "            feature_importances.append(fold_importance)\n",
    "        \n",
    "        if not fold_metrics:\n",
    "            raise ValueError(\"No valid folds found. Check if your data contains both classes.\")\n",
    "        \n",
    "        # Calculate mean feature importance across folds\n",
    "        self.feature_importances_ = np.mean(feature_importances, axis=0)\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        overall_metrics = {\n",
    "            'mean_auc': np.mean([m['auc'] for m in fold_metrics]),\n",
    "            'std_auc': np.std([m['auc'] for m in fold_metrics]),\n",
    "            'mean_pr_auc': np.mean([m['pr_auc'] for m in fold_metrics]),\n",
    "            'std_pr_auc': np.std([m['pr_auc'] for m in fold_metrics]),\n",
    "            'mean_positive_ratio': np.mean([m['positive_ratio'] for m in fold_metrics])\n",
    "        }\n",
    "        \n",
    "        return fold_metrics, overall_metrics, all_predictions, all_true_values\n",
    "    \n",
    "    def plot_feature_importance(self, feature_names, top_n=20):\n",
    "        feat_imp = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': self.feature_importances_\n",
    "        })\n",
    "        \n",
    "        feat_imp = feat_imp.sort_values('Importance', ascending=False).head(top_n)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(x='Importance', y='Feature', data=feat_imp)\n",
    "        plt.title(f'Top {top_n} Most Important Features (Ensemble Model)')\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return feat_imp\n",
    "    \n",
    "    def plot_metrics(self, fold_metrics):\n",
    "        metrics_df = pd.DataFrame(fold_metrics)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        sns.boxplot(y='auc', data=metrics_df, ax=axes[0])\n",
    "        axes[0].set_title('AUC Score Distribution')\n",
    "        \n",
    "        sns.boxplot(y='pr_auc', data=metrics_df, ax=axes[1])\n",
    "        axes[1].set_title('PR-AUC Score Distribution')\n",
    "        \n",
    "        sns.boxplot(y='positive_ratio', data=metrics_df, ax=axes[2])\n",
    "        axes[2].set_title('Positive Class Ratio Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "df = prepare_data(data)\n",
    "X, y, feature_cols = create_features(df)\n",
    "\n",
    "# Check class balance\n",
    "print(f\"Class distribution:\\n{y.value_counts(normalize=True)}\")\n",
    "\n",
    "ensemble = EnsembleInjuryPredictor(weights=[0.3, 0.4, 0.3])\n",
    "fold_metrics, overall_metrics, predictions, true_values = ensemble.train_and_evaluate(X, y)\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Mean AUC: {overall_metrics['mean_auc']:.3f} Â± {overall_metrics['std_auc']:.3f}\")\n",
    "print(f\"Mean PR-AUC: {overall_metrics['mean_pr_auc']:.3f} Â± {overall_metrics['std_pr_auc']:.3f}\")\n",
    "print(f\"Mean Positive Ratio: {overall_metrics['mean_positive_ratio']:.3f}\")\n",
    "\n",
    "feature_importance_df = ensemble.plot_feature_importance(feature_cols)\n",
    "ensemble.plot_metrics(fold_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    date_columns = ['Date', 'problem_date', 'return_date', 'reported_date']\n",
    "\n",
    "    df = df.dropna(subset=date_columns)\n",
    "\n",
    "    for col in date_columns:\n",
    "        df.loc[:,col] = [parser.parse(date) for date in df[col]]\n",
    "\n",
    "    df = df.sort_values('Date')\n",
    "    \n",
    "    # Create injury indicator (1 if injury occurred within next 14 days)\n",
    "    df['next_injury'] = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        future_injuries = df[\n",
    "            (df['problem_date'] > row['Date']) & \n",
    "            (df['problem_date'] <= row['Date'] + pd.Timedelta(days=14))\n",
    "        ]\n",
    "        if len(future_injuries) > 0:\n",
    "            df.at[idx, 'next_injury'] = 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    exclude_cols = ['Date', 'problem_date', 'return_date', 'reported_date', \n",
    "                    'next_injury', 'athlete_code', 'TestId']\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols and \n",
    "                   df[col].dtype in ['float64', 'int64']]\n",
    "    \n",
    "    X = df[feature_cols].ffill().replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    y = df['next_injury']\n",
    "    \n",
    "    return X, y, feature_cols\n",
    "\n",
    "def train_and_evaluate(X, y):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    feature_importances = []\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n",
    "            X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "            X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "        \n",
    "        rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "        feature_importances.append(rf.feature_importances_)\n",
    "    \n",
    "    mean_importances = np.mean(feature_importances, axis=0)\n",
    "    \n",
    "    return mean_importances\n",
    "\n",
    "def plot_feature_importance(importances, feature_names, top_n=20):\n",
    "    feat_imp = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    })\n",
    "    \n",
    "    feat_imp = feat_imp.sort_values('Importance', ascending=False).head(top_n)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feat_imp)\n",
    "    plt.title(f'Top {top_n} Most Important Features for Injury Prediction')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_xgb(X, y):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.1,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    feature_importances = []\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n",
    "            X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "            X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "        dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "        \n",
    "        model = xgb.train(\n",
    "            xgb_params,\n",
    "            dtrain,\n",
    "            num_boost_round=100,\n",
    "            evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        importance_scores = model.get_score(importance_type='gain')\n",
    "        importance_array = np.zeros(X.shape[1])\n",
    "        for feat, score in importance_scores.items():\n",
    "            importance_array[int(feat.replace('f', ''))] = score\n",
    "        \n",
    "        feature_importances.append(importance_array)\n",
    "    \n",
    "    mean_importances = np.mean(feature_importances, axis=0)\n",
    "    \n",
    "    return mean_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_lgbm(X, y):\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    \n",
    "    lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,  # roughly equivalent to max_depth=5\n",
    "        'learning_rate': 0.1,\n",
    "        'feature_fraction': 0.8,  # similar to colsample_bytree\n",
    "        'bagging_fraction': 0.8,  # similar to subsample\n",
    "        'bagging_freq': 1,\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    num_boost_round = 100\n",
    "    early_stopping_rounds = 10\n",
    "    \n",
    "    feature_importances = []\n",
    "    \n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        if np.isnan(X_train_scaled).any() or np.isnan(X_test_scaled).any():\n",
    "            X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "            X_test_scaled = np.nan_to_num(X_test_scaled)\n",
    "        \n",
    "        train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)\n",
    "        \n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            num_boost_round=num_boost_round,\n",
    "            valid_sets=[train_data, valid_data],\n",
    "            valid_names=['train', 'valid'],\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(early_stopping_rounds),\n",
    "                lgb.log_evaluation(period=-1)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        importance_array = model.feature_importance(importance_type='gain')\n",
    "        feature_importances.append(importance_array)\n",
    "    \n",
    "    mean_importances = np.mean(feature_importances, axis=0)\n",
    "    \n",
    "    return mean_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    df = prepare_data(data)\n",
    "\n",
    "    #df.drop([\"Right Avg. Landing Force\", \"Right Avg. Landing Force\"],axis=1, inplace=True)\n",
    "\n",
    "    X, y, feature_cols = create_features(df)\n",
    "\n",
    "    #importances = train_and_evaluate(X, y)\n",
    "    importances = train_and_evaluate_xgb(X, y)\n",
    "    #importances = train_and_evaluate_lgbm(X, y)\n",
    "\n",
    "    feat_imp = plot_feature_importance(importances, feature_cols)\n",
    "    \n",
    "    return feat_imp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    feature_importance_results = main()\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance_results.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
